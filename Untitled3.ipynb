{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d298832",
   "metadata": {},
   "source": [
    "# Visualizing Decision Boundaries in 3D: An Extension of Discriminative-vs-QDA-One-Gaussian.ipynb\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook serves as an extension of the original `Discriminative-vs-QDA-One-Gaussian.ipynb` project, where we compared the performance of a discriminative model with a manually implemented Quadratic Discriminant Analysis (QDA) on data generated from a single Gaussian distribution. \n",
    "\n",
    "In this extension, we focus on visualizing the decision boundaries in a 3-dimensional space (dim=3). By leveraging the `mayavi` library, we can create interactive 3D plots that provide deeper insights into how these models separate the data when the dimensionality is increased. This visualization is crucial for understanding the geometric properties of decision boundaries in higher dimensions and how well each model adapts to the data's underlying structure.\n",
    "\n",
    "The notebook will cover the following steps:\n",
    "1. Data generation from a 3-dimensional Gaussian distribution.\n",
    "2. Training both the discriminative model and the QDA model on this 3D data.\n",
    "3. Visualizing the decision boundaries using `mayavi` to explore the differences between the models in a 3D space.\n",
    "4. Comparing the models' performances through misclassification error rates across different sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "WARNING: Imported VTK version (9.3) does not match the one used\n",
      "         to build the TVTK classes (9.2). This may cause problems.\n",
      "         Please rebuild TVTK.\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhcho\\AppData\\Local\\Temp\\ipykernel_18140\\4197217287.py:65: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
      "  self.B = (Sigma_2_inv @ mu_2 - Sigma_1_inv @ mu_1).T\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from mayavi import mlab\n",
    "\n",
    "def generate_cov_matrix():\n",
    "    L = torch.tril(torch.randn(dim, dim))\n",
    "    L.diagonal().copy_(torch.rand(dim) + 1)  # ensure positive diagonal elements\n",
    "    cov_matrix = torch.mm(L, L.t())  # L * L^T guarantees a positive definite matrix\n",
    "    return cov_matrix\n",
    "\n",
    "def generate_data(n):\n",
    "    # Create M with only the first three rows and columns non-zero\n",
    "    M = torch.zeros(dim, dim)\n",
    "    M[:2, :2] = torch.randn(2, 2)\n",
    "    \n",
    "    # Ensure positive diagonal entries in the top-left 3x3 block for positive definiteness\n",
    "    M.diagonal()[:2] = torch.rand(2) + 1.0\n",
    "    \n",
    "    # Compute A_True as M * M^T and adjust it to have only the first three non-zero rows and columns\n",
    "    A_True = torch.mm(M, M.t())\n",
    "    A_True[2:, :] = 0\n",
    "    A_True[:, 2:] = 0\n",
    "    \n",
    "    # Adjust B_True similarly\n",
    "    B_True = torch.zeros(dim, 1)\n",
    "    B_True[:2] = torch.randn(2, 1)\n",
    "\n",
    "    Mu_true = torch.full((dim,), 0.1, dtype=torch.float32)\n",
    "    cov_true = generate_cov_matrix()\n",
    "    \n",
    "    dist = MultivariateNormal(Mu_true, cov_true)\n",
    "    x = dist.sample((n,))\n",
    "\n",
    "    # Calculate the quadratic form for the classifier\n",
    "    term1 = torch.sum((x @ A_True) * x, dim=1)\n",
    "    term2 = (x @ B_True).squeeze()\n",
    "    c_True = -torch.mean(term1 + term2)\n",
    "    y = torch.sign(term1 + term2 + c_True)\n",
    "\n",
    "    return x, y, A_True, B_True, c_True\n",
    "\n",
    "# Manual QDA Implementation\n",
    "class ManualQDA:\n",
    "    def __init__(self):\n",
    "        self.A = None\n",
    "        self.B = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        class_1 = x[y == 1]\n",
    "        class_2 = x[y == -1]\n",
    "        mu_1 = torch.mean(class_1, axis=0)\n",
    "        mu_2 = torch.mean(class_2, axis=0)\n",
    "        Sigma_1 = torch.cov(class_1.T)\n",
    "        Sigma_2 = torch.cov(class_2.T)\n",
    "        Sigma_1_inv = torch.inverse(Sigma_1)\n",
    "        Sigma_2_inv = torch.inverse(Sigma_2)\n",
    "\n",
    "        self.A = 0.5*(Sigma_1_inv - Sigma_2_inv)\n",
    "        self.B = (Sigma_2_inv @ mu_2 - Sigma_1_inv @ mu_1).T\n",
    "        self.c = 0.5*(mu_1.T @ Sigma_1_inv @ mu_1 - mu_2.T @ Sigma_2_inv @ mu_2 + torch.logdet(Sigma_1) - torch.logdet(Sigma_2))\n",
    "\n",
    "    def decision_function(self, x):\n",
    "        # Compute x^T A x + B^T x + c\n",
    "        quad_form = torch.sum((x @ self.A) * x, dim=1)\n",
    "        linear_form = torch.matmul(x, self.B)\n",
    "        const_term = self.c\n",
    "        decision_scores = quad_form + linear_form + const_term\n",
    "        return decision_scores\n",
    "\n",
    "    def predict(self, x):\n",
    "        scores = self.decision_function(x)\n",
    "        return -torch.sign(scores)\n",
    "\n",
    "### Discriminative Model Training\n",
    "def train_discriminative_model(x, y, epochs=300, batch_size=64):\n",
    "    # Convert to PyTorch tensors if not already\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    if not isinstance(y, torch.Tensor):\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    A = torch.zeros((dim, dim), requires_grad=True)\n",
    "    B = torch.zeros((dim, 1), requires_grad=True)\n",
    "    C = torch.zeros(1, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([A, B, C], lr=0.01)\n",
    "    scheduler = StepLR(optimizer, step_size=25, gamma=0.1)  # Reduce LR by a factor of 0.1 every 25 epochs\n",
    "    error_history = []\n",
    "\n",
    "    # Prepare DataLoader for mini-batch processing\n",
    "    dataset = TensorDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = torch.sum((batch_x @ A) * batch_x, dim=1) + (batch_x @ B + C).squeeze()\n",
    "            loss = torch.mean(torch.log(1 + torch.exp(-batch_y * yhat)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()  # Adjust the learning rate according to the scheduler\n",
    "\n",
    "        # Evaluate misclassification error at each epoch using all data\n",
    "        with torch.no_grad():\n",
    "            yhat = torch.sum((x @ A) * x, dim=1) + (x @ B + C).squeeze()\n",
    "            predictions = torch.sign(yhat)\n",
    "            misclassification_error = (predictions != y).float().mean().item()\n",
    "            error_history.append(misclassification_error)\n",
    "\n",
    "    return A, B, C, error_history\n",
    "\n",
    "def evaluate_model(x, y, A, B, C):\n",
    "    with torch.no_grad():\n",
    "        yhat = torch.sum((x @ A) * x, dim=1) + (x @ B + C).squeeze()\n",
    "        predictions = torch.sign(yhat)\n",
    "        misclassification_error = (predictions != y).float().mean().item()\n",
    "    return misclassification_error\n",
    "\n",
    "# Manual QDA Training and Evaluation\n",
    "def train_and_evaluate_manual_qda(x_train, y_train, x_test, y_test):\n",
    "    qda = ManualQDA()\n",
    "    qda.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    y_pred_train = qda.predict(x_train)\n",
    "    error_train = (y_pred_train != y_train).float().mean().item()\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred_test = qda.predict(x_test)\n",
    "    error_test = (y_pred_test != y_test).float().mean().item()\n",
    "\n",
    "    return error_train, error_test\n",
    "\n",
    "def plot_decision_boundaries(qda_model, disc_model, x, y, A_True, B_True, title=\"Comparison of Decision Boundaries\"):\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    z_min, z_max = x[:, 2].min() - 1, x[:, 2].max() + 1\n",
    "    \n",
    "    if dim == 2:\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, num=400), np.linspace(y_min, y_max, num=400))\n",
    "        mesh_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "        # Create a mesh to plot the decision boundaries\n",
    "        x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "        y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, num=400), np.linspace(y_min, y_max, num=400))\n",
    "        mesh_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "        # Evaluate the QDA classifier on all the grid points\n",
    "        Z_qda = qda_model.decision_function(mesh_points)\n",
    "        Z_qda = Z_qda.reshape(xx.shape)\n",
    "    \n",
    "        # Evaluate the Discriminative model on all the grid points\n",
    "        model_outputs = disc_model(mesh_points).detach().numpy()\n",
    "        Z_disc = model_outputs.reshape(xx.shape)\n",
    "    \n",
    "        # Calculate the true decision boundary using A_True and B_True\n",
    "        # True constant term calculation\n",
    "        Z_true = torch.sum((mesh_points @ A_True) * mesh_points, dim=1) + torch.matmul(mesh_points, B_True).squeeze() + c_True\n",
    "        Z_true = Z_true.detach().numpy().reshape(xx.shape)\n",
    "    \n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.contourf(xx, yy, Z_qda, levels=[-1, 0, 1], cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        plt.contour(xx, yy, Z_qda, levels=[0], colors='k', linestyles='--')\n",
    "        plt.scatter(x[:, 0], x[:, 1], c=-y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "        plt.title(f\"QDA - {title}\")\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "    \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.contourf(xx, yy, Z_disc, levels=[-1, 0, 1], cmap=plt.cm.viridis, alpha=0.5)\n",
    "        plt.contour(xx, yy, Z_disc, levels=[0], cmap=\"RdBu_r\")\n",
    "        plt.scatter(x[:, 0], x[:, 1], c=y, cmap=plt.cm.viridis, s=20, edgecolors='k')\n",
    "        plt.title(f\"Discriminative - {title}\")\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "    \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.contourf(xx, yy, Z_true, levels=[-1, 0, 1], cmap=plt.cm.Pastel1, alpha=0.8)\n",
    "        plt.contour(xx, yy, Z_true, levels=[0], colors='k', linestyles='--')\n",
    "        plt.scatter(x[:, 0], x[:, 1], c=y, cmap=plt.cm.Pastel1, s=20, edgecolors='k')\n",
    "        plt.title(f\"True - {title}\")\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif dim == 3:\n",
    "        # Generate a 3D grid\n",
    "        xx, yy, zz = np.meshgrid(np.linspace(x_min, x_max, num=40), \n",
    "                                 np.linspace(y_min, y_max, num=40),\n",
    "                                 np.linspace(z_min, z_max, num=40), indexing='ij')\n",
    "        mesh_points = torch.tensor(np.vstack([xx.ravel(), yy.ravel(), zz.ravel()]).T, dtype=torch.float32)\n",
    "    \n",
    "        # Evaluate the models on all the grid points\n",
    "        Z_qda = qda_model.decision_function(mesh_points).reshape(xx.shape)\n",
    "        model_outputs = disc_model(mesh_points).detach().numpy()\n",
    "        Z_disc = model_outputs.reshape(xx.shape)\n",
    "        Z_true = (torch.sum((mesh_points @ A_True) * mesh_points, dim=1) + \n",
    "                  torch.matmul(mesh_points, B_True).squeeze() + c_True).detach().numpy().reshape(xx.shape)\n",
    "    \n",
    "        # Scatter plot for actual data points based on labels\n",
    "        points_label_1 = x[y == 1]\n",
    "        points_label_neg1 = x[y == -1]\n",
    "    \n",
    "        # Plotting the QDA decision boundary\n",
    "        mlab.figure(bgcolor=(1, 1, 1), size=(800, 600), fgcolor=(0, 0, 0))  # Black foreground color\n",
    "        mlab.clf()  # Clear the current figure\n",
    "        mlab.contour3d(xx, yy, zz, Z_qda, contours=[0], opacity=0.5, colormap='cool')\n",
    "        mlab.points3d(points_label_1[:, 0], points_label_1[:, 1], points_label_1[:, 2], color=(1, 0, 0), scale_factor=0.1)  # Red for label 1\n",
    "        mlab.points3d(points_label_neg1[:, 0], points_label_neg1[:, 1], points_label_neg1[:, 2], color=(0, 0, 1), scale_factor=0.1)  # Blue for label -1\n",
    "        mlab.title(f\"QDA - {title}, Sample Size: {sample_sizes}\", size=0.5)\n",
    "        mlab.xlabel(\"Feature 1\")\n",
    "        mlab.ylabel(\"Feature 2\")\n",
    "        mlab.zlabel(\"Feature 3\")\n",
    "        mlab.show()\n",
    "    \n",
    "        # Plotting the Discriminative model decision boundary\n",
    "        mlab.figure(bgcolor=(1, 1, 1), size=(800, 600), fgcolor=(0, 0, 0))\n",
    "        mlab.clf()\n",
    "        mlab.contour3d(xx, yy, zz, Z_disc, contours=[0], opacity=0.5, colormap='viridis')\n",
    "        mlab.points3d(points_label_1[:, 0], points_label_1[:, 1], points_label_1[:, 2], color=(1, 0, 0), scale_factor=0.1)  # Red for label 1\n",
    "        mlab.points3d(points_label_neg1[:, 0], points_label_neg1[:, 1], points_label_neg1[:, 2], color=(0, 0, 1), scale_factor=0.1)  # Blue for label -1\n",
    "        mlab.title(f\"Discriminative - {title}, Sample Size: {sample_sizes}\", size=0.5)\n",
    "        mlab.xlabel(\"Feature 1\")\n",
    "        mlab.ylabel(\"Feature 2\")\n",
    "        mlab.zlabel(\"Feature 3\")\n",
    "        mlab.show()\n",
    "    \n",
    "        # Plotting the True decision boundary\n",
    "        mlab.figure(bgcolor=(1, 1, 1), size=(800, 600), fgcolor=(0, 0, 0))\n",
    "        mlab.clf()\n",
    "        mlab.contour3d(xx, yy, zz, Z_true, contours=[0], opacity=0.5, colormap='autumn')\n",
    "        mlab.points3d(points_label_1[:, 0], points_label_1[:, 1], points_label_1[:, 2], color=(1, 0, 0), scale_factor=0.1)  # Red for label 1\n",
    "        mlab.points3d(points_label_neg1[:, 0], points_label_neg1[:, 1], points_label_neg1[:, 2], color=(0, 0, 1), scale_factor=0.1)  # Blue for label -1\n",
    "        mlab.title(f\"True - {title}, Sample Size: {sample_sizes}\", size=0.5)\n",
    "        mlab.xlabel(\"Feature 1\")\n",
    "        mlab.ylabel(\"Feature 2\")\n",
    "        mlab.zlabel(\"Feature 3\")\n",
    "        mlab.show()\n",
    "\n",
    "################# Simulation #################\n",
    "    \n",
    "# Simulation with multiple seeds\n",
    "dim=3\n",
    "sample_sizes = [100, 300, 1000, 3000]\n",
    "results = []\n",
    "seeds = [1223, 13242, 13252, 1718, 132152]\n",
    "\n",
    "for n in sample_sizes:\n",
    "    avg_errors_disc_train, avg_errors_disc_test, avg_errors_qda_train, avg_errors_qda_test = [], [], [], []\n",
    "\n",
    "    \n",
    "    # Initialize a flag to control the plotting\n",
    "    plotted = False\n",
    "    \n",
    "    for seed in seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        errors_disc_train, errors_disc_test, errors_qda_train, errors_qda_test = [], [], [], []\n",
    "\n",
    "        for i in range(5):  # Train 5 times with different splits but same initial seed setup\n",
    "            x, y, A_True, B_True, c_True = generate_data(n)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "            \n",
    "            # Discriminative model training and evaluation\n",
    "            A, B, C, error_history = train_discriminative_model(x_train, y_train)\n",
    "            error_disc_train = evaluate_model(x_train, y_train, A, B, C)\n",
    "            error_disc_test = evaluate_model(x_test, y_test, A, B, C)\n",
    "            errors_disc_train.append(error_disc_train)\n",
    "            errors_disc_test.append(error_disc_test)\n",
    "\n",
    "            # QDA training and evaluation\n",
    "            qda_model = ManualQDA()\n",
    "            qda_model.fit(x_train, y_train)\n",
    "            error_qda_train, error_qda_test = train_and_evaluate_manual_qda(x_train, y_train, x_test, y_test)\n",
    "            errors_qda_train.append(error_qda_train)\n",
    "            errors_qda_test.append(error_qda_test)\n",
    "            \n",
    "            if (dim == 2 or dim == 3) and not plotted:\n",
    "                if seed == seeds[0] and i == 0:\n",
    "                    def disc_model_predict(mesh_points):\n",
    "                        # This function uses the latest values of A, B, and C to predict labels\n",
    "                        return torch.sum((mesh_points @ A) * mesh_points, dim=1) + (mesh_points @ B + C).squeeze()\n",
    "                \n",
    "                    # Call the plot function with all required parameters\n",
    "                    plot_decision_boundaries(qda_model, disc_model_predict, x_train, y_train, A_True, B_True, title=f\"Sample Size {n}\")\n",
    "                    plotted = True  # Set the flag to true after plotting\n",
    "            \n",
    "            avg_errors_disc_train.append(np.mean(errors_disc_train))\n",
    "            avg_errors_disc_test.append(np.mean(errors_disc_test))\n",
    "            avg_errors_qda_train.append(np.mean(errors_qda_train))\n",
    "            avg_errors_qda_test.append(np.mean(errors_qda_test))\n",
    "\n",
    "    results.append((n, np.mean(avg_errors_disc_train), np.mean(avg_errors_disc_test), \n",
    "                    np.mean(avg_errors_qda_train), np.mean(avg_errors_qda_test)))\n",
    "\n",
    "\n",
    "# Plot for Average Misclassification Error\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title('Average Misclassification Error Comparison')\n",
    "plt.plot(sample_sizes, [r[1] for r in results], label='Discriminative Model Train', marker='o', color='blue')\n",
    "plt.plot(sample_sizes, [r[2] for r in results], label='Discriminative Model Test', linestyle='--', marker='x', color='blue')\n",
    "plt.plot(sample_sizes, [r[3] for r in results], label='QDA Model Train', marker='o', color='red')\n",
    "plt.plot(sample_sizes, [r[4] for r in results], label='QDA Model Test', linestyle='--', marker='x', color='red')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Average Misclassification Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
